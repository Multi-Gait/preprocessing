### .NPY Dataset Field Descriptions  


#### **Dataset Structure and Quick Start**  
For quick experimentation, we provide preprocessed `.npy` files generated by the [mat2npy.py](https://github.com/Multi-Gait/preprocessing/blob/d6258e5dc3fa3f39d40dec6eb8b259ab82d1619e/Scripts/Mat2Npy/mat2npy.py) script. The dataset can be downloaded from the [Dropbox Link](https://www.dropbox.com/scl/fo/0lz1zqmw0ku0kr04m29mq/AEvwNYA8tv4TXFoKil-wT9Y?rlkey=hhbnj12x268vw9yy3bi23koyk&st=8gqgfdhs&dl=0).  


#### **Field-by-Field Description**  
The dataset contains the following `.npy` files, with each field organized by participant and modality. Note that data for 34 participants is split into 3 files (X=1,2,3) for easier handling; concatenate them to get the full dataset.  

- **N=680** represents the total number of gait samples.  
- **Seq length=20**: Each sample contains the last 20 frames of a gait sequence (adjustable per research needs).  

| **File Name**                          | **Content Description**                                                                 | **Data Format**                          |
|----------------------------------------|---------------------------------------------------------------------------------------|------------------------------------------|
| `list_label_all_X.npy`                 | Participant ID labels (1-34).                                                         | 1D array of integers (shape: [N,])       |
| `list_all_gender_X.npy`                | Gender labels (0 = female, 1 = male).                                                 | 1D array of integers (shape: [N,])       |
| `list_all_pc_raw_rdi_X.npy`            | Millimeter-wave (mmWave) Range-Doppler heatmaps, capturing frequency-domain motion features. | 4D array (shape: [N, Seq, 128, 224]) where 128 is range bins, 224 is doppler bins. |
| `list_all_pc_xyziv_ti_X.npy`           | mmWave point clouds with 3D coordinates (X,Y,Z), intensity (I), velocity (V). | 4D array (shape: [N, Seq, num_points, 5]) where we unify num_points to 64, each row contains [X, Y, Z, I, V] |
| `list_all_image_front_X.npy`           | Front-view RGB images captured by a Kinect depth camera.                               | 5D array (shape: [N, Seq, height, width, 3])  |
| `list_all_image_side_X.npy`            | Side-view RGB images captured by a secondary camera.                                   | 5D array (shape: [N, Seq, height, width, 3])  |
| `list_all_kinect_key_X.npy`            | 3D skeleton keypoints from Kinect (joint positions in camera coordinate system).       | 4D array (shape: [N, Seq, num_keypoints, 3]) where num_keypoints is 32  |
| `list_all_smpl_joints_X.npy`           | SMPL skeleton keypoints (human pose in standard joint representation).                | 4D array (shape: [N, Seq, num_smpl_joints, 3]) where num_smpl_joints is 24|
| `list_all_smpl_verts_X.npy`            | SMPL skinned vertices (3D mesh surface coordinates).                                   | 4D array (shape: [N, Seq, num_vertices, 4]) where num_vertices is 6890, 4 contains [X, Y, Z, V] |


#### **Dataset Splitting Logic**  
- **Total participants**: 34  
- **Files per participant group**: 3 (X=1,2,3)  
- **Data distribution example**:  
  - `X=1`: Participants 1-12  
  - `X=2`: Participants 13-24  
  - `X=3`: Participants 25-34  
- **Concatenation example (Python)**:  
  ```python
  import numpy as np
  
  # Concatenate participant IDs
  labels = np.concatenate([
      np.load('list_label_all_1.npy'),
      np.load('list_label_all_2.npy'),
      np.load('list_label_all_3.npy')
  ])
  ```
